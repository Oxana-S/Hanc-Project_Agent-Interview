"""
AnketaMarkdownParser - parses edited Markdown back into FinalAnketa.

Extracts data from the markdown format generated by AnketaGenerator
and merges changes back into the FinalAnketa model.
"""

import re
from typing import List, Optional, Tuple

import structlog

from src.anketa.schema import (
    FinalAnketa, AgentFunction, Integration,
    FAQItem, ObjectionHandler, DialogueExample, FinancialMetric,
    Competitor, MarketInsight, EscalationRule, KPIMetric,
    ChecklistItem, AIRecommendation, TargetAudienceSegment
)

logger = structlog.get_logger()


class AnketaMarkdownParser:
    """Parses Markdown anketa back into FinalAnketa model."""

    def parse(self, content: str, base: FinalAnketa) -> FinalAnketa:
        """
        Parse Markdown v2.0 and merge changes with base anketa.

        Args:
            content: Edited Markdown content
            base: Original FinalAnketa to merge with

        Returns:
            Updated FinalAnketa with changes from Markdown
        """
        logger.info("Parsing markdown anketa v2.0")

        # Start with base data
        data = base.model_dump()

        # Parse basic sections
        data.update(self._parse_company_info(content))
        data.update(self._parse_business_context(content))
        data.update(self._parse_voice_agent(content))
        data.update(self._parse_agent_functions(content))
        data.update(self._parse_integrations(content))

        # Parse v2.0 sections
        data.update(self._parse_faq_items(content))
        data.update(self._parse_objection_handlers(content))
        data.update(self._parse_sample_dialogue(content))
        data.update(self._parse_financial_metrics(content))
        data.update(self._parse_market_analysis(content))
        data.update(self._parse_target_segments(content))
        data.update(self._parse_escalation_rules(content))
        data.update(self._parse_success_kpis(content))
        data.update(self._parse_launch_checklist(content))
        data.update(self._parse_ai_recommendations(content))
        data.update(self._parse_tone_of_voice(content))
        data.update(self._parse_error_handling_scripts(content))
        data.update(self._parse_follow_up_sequence(content))

        # Preserve metadata from base
        data['created_at'] = base.created_at
        data['consultation_duration_seconds'] = base.consultation_duration_seconds
        data['anketa_version'] = base.anketa_version

        logger.info("Markdown v2.0 parsed successfully")
        return FinalAnketa(**data)

    def _parse_company_info(self, content: str) -> dict:
        """Parse company information from table."""
        result = {}

        # Extract table values
        patterns = {
            'company_name': r'\| ÐšÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ñ \| (.+?) \|',
            'industry': r'\| ÐžÑ‚Ñ€Ð°ÑÐ»ÑŒ \| (.+?) \|',
            'specialization': r'\| Ð¡Ð¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ \| (.+?) \|',
            'website': r'\| Ð¡Ð°Ð¹Ñ‚ \| (.+?) \|',
            'contact_name': r'\| ÐšÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ð½Ð¾Ðµ Ð»Ð¸Ñ†Ð¾ \| (.+?) \|',
            'contact_role': r'\| Ð”Ð¾Ð»Ð¶Ð½Ð¾ÑÑ‚ÑŒ \| (.+?) \|',
        }

        for field, pattern in patterns.items():
            match = re.search(pattern, content)
            if match:
                value = match.group(1).strip()
                if value and value != 'â€”':
                    result[field] = value
                elif field in ('website',):
                    result[field] = None
                else:
                    result[field] = ''

        # Parse business description
        desc_match = re.search(
            r'### ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð±Ð¸Ð·Ð½ÐµÑÐ°\n\n(.+?)(?=\n###|\n---)',
            content,
            re.DOTALL
        )
        if desc_match:
            desc = desc_match.group(1).strip()
            if desc != '*ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾*':
                result['business_description'] = desc

        # Parse services list
        result['services'] = self._parse_list_section(content, 'Ð£ÑÐ»ÑƒÐ³Ð¸ / ÐŸÑ€Ð¾Ð´ÑƒÐºÑ‚Ñ‹')
        result['client_types'] = self._parse_list_section(content, 'Ð¢Ð¸Ð¿Ñ‹ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð²')

        return result

    def _parse_business_context(self, content: str) -> dict:
        """Parse business context section."""
        return {
            'current_problems': self._parse_list_section(content, 'Ð¢ÐµÐºÑƒÑ‰Ð¸Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹'),
            'business_goals': self._parse_list_section(content, 'Ð¦ÐµÐ»Ð¸ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ð¸Ð¸'),
            'constraints': self._parse_list_section(content, 'ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ'),
        }

    def _parse_voice_agent(self, content: str) -> dict:
        """Parse voice agent configuration."""
        result = {}

        # Extract table values
        patterns = {
            'agent_name': r'\| Ð˜Ð¼Ñ Ð°Ð³ÐµÐ½Ñ‚Ð° \| (.+?) \|',
            'agent_purpose': r'\| ÐÐ°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ \| (.+?) \|',
            'language': r'\| Ð¯Ð·Ñ‹Ðº \| (.+?) \|',
        }

        for field, pattern in patterns.items():
            match = re.search(pattern, content)
            if match:
                value = match.group(1).strip()
                if value and value != 'â€”':
                    result[field] = value

        # Parse voice (format: "female, professional")
        voice_match = re.search(r'\| Ð“Ð¾Ð»Ð¾Ñ \| (.+?) \|', content)
        if voice_match:
            voice_str = voice_match.group(1).strip()
            parts = [p.strip() for p in voice_str.split(',')]
            if len(parts) >= 1:
                result['voice_gender'] = parts[0]
            if len(parts) >= 2:
                result['voice_tone'] = parts[1]

        # Parse call direction
        direction_match = re.search(r'\| Ð¢Ð¸Ð¿ Ð·Ð²Ð¾Ð½ÐºÐ¾Ð² \| (.+?) \|', content)
        if direction_match:
            direction_str = direction_match.group(1).strip()
            direction_map = {
                'Ð’Ñ…Ð¾Ð´ÑÑ‰Ð¸Ðµ': 'inbound',
                'Ð˜ÑÑ…Ð¾Ð´ÑÑ‰Ð¸Ðµ': 'outbound',
                'Ð’Ñ…Ð¾Ð´ÑÑ‰Ð¸Ðµ Ð¸ Ð¸ÑÑ…Ð¾Ð´ÑÑ‰Ð¸Ðµ': 'both',
            }
            result['call_direction'] = direction_map.get(direction_str, 'inbound')

        # Parse typical questions (FAQ)
        result['typical_questions'] = self._parse_list_section(
            content, 'Ð¢Ð¸Ð¿Ð¸Ñ‡Ð½Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ (FAQ)'
        )

        return result

    def _parse_agent_functions(self, content: str) -> dict:
        """Parse agent functions from numbered sections."""
        result = {
            'agent_functions': [],
            'main_function': None,
            'additional_functions': [],
        }

        # Find "Ð’ÑÐµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð°Ð³ÐµÐ½Ñ‚Ð°" section
        functions_section = re.search(
            r'## 4\. Ð’ÑÐµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð°Ð³ÐµÐ½Ñ‚Ð°\n\n(.+?)(?=\n---|\Z)',
            content,
            re.DOTALL
        )

        if not functions_section:
            return result

        section_content = functions_section.group(1)

        # Parse each numbered function
        function_pattern = r'### (\d+)\. (.+?)\n\n(.+?)(?=\n### \d+\.|\n\*ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚:|$)'
        priority_pattern = r'\*ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚: (\w+)\*'

        functions = []
        matches = list(re.finditer(function_pattern, section_content, re.DOTALL))

        for match in matches:
            num = int(match.group(1))
            name = match.group(2).strip()
            description = match.group(3).strip()

            # Find priority after description
            remaining = section_content[match.end():]
            priority_match = re.search(priority_pattern, remaining[:100])
            priority = priority_match.group(1) if priority_match else 'medium'

            # Clean description (remove priority line if present)
            description = re.sub(r'\n\*ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚: \w+\*', '', description).strip()

            func = AgentFunction(
                name=name,
                description=description,
                priority=priority
            )
            functions.append((num, func))

        # Sort by number and assign
        functions.sort(key=lambda x: x[0])
        all_functions = [f for _, f in functions]

        result['agent_functions'] = all_functions

        if all_functions:
            result['main_function'] = all_functions[0]
            result['additional_functions'] = all_functions[1:] if len(all_functions) > 1 else []

        return result

    def _parse_integrations(self, content: str) -> dict:
        """Parse integrations from table."""
        integrations = []

        # Find integrations section
        integ_section = re.search(
            r'## 5\. Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¸\n\n(.+?)(?=\n---|\Z)',
            content,
            re.DOTALL
        )

        if not integ_section:
            return {'integrations': integrations}

        section_content = integ_section.group(1)

        # Check if no integrations
        if 'Ð½Ðµ Ñ‚Ñ€ÐµÐ±ÑƒÑŽÑ‚ÑÑ' in section_content.lower():
            return {'integrations': integrations}

        # Parse table rows
        row_pattern = r'\| (.+?) \| (.+?) \| (Ð”Ð°|ÐÐµÑ‚) \|'
        for match in re.finditer(row_pattern, section_content):
            name = match.group(1).strip()
            purpose = match.group(2).strip()
            required = match.group(3).strip() == 'Ð”Ð°'

            # Skip header row
            if name in ('Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð°', '------'):
                continue

            integrations.append(Integration(
                name=name,
                purpose=purpose,
                required=required
            ))

        return {'integrations': integrations}

    def _parse_list_section(self, content: str, section_name: str) -> List[str]:
        """Parse a bulleted list section."""
        # Find section
        pattern = rf'### {re.escape(section_name)}\n\n(.+?)(?=\n###|\n---|\n## )'
        match = re.search(pattern, content, re.DOTALL)

        if not match:
            return []

        section_content = match.group(1).strip()

        if section_content == '*ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾*':
            return []

        # Parse bullet points
        items = []
        for line in section_content.split('\n'):
            line = line.strip()
            if line.startswith('- '):
                item = line[2:].strip()
                if item:
                    items.append(item)

        return items

    # =========================================================================
    # V2.0 PARSING METHODS
    # =========================================================================

    def _parse_faq_items(self, content: str) -> dict:
        """Parse FAQ items with answers."""
        items = []

        section = self._extract_section(content, r'## 6\. FAQ Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð°Ð¼Ð¸')
        if not section or 'Ð½Ðµ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½' in section.lower():
            return {'faq_items': items}

        # Pattern: ### N. Question [category]
        pattern = r'### \d+\. (.+?)(?:\s*\[(\w+)\])?\n\n> (.+?)(?=\n### \d+\.|\Z)'
        for match in re.finditer(pattern, section, re.DOTALL):
            question = match.group(1).strip()
            category = match.group(2) or 'general'
            answer = match.group(3).strip()

            items.append(FAQItem(
                question=question,
                answer=answer,
                category=category
            ))

        return {'faq_items': items}

    def _parse_objection_handlers(self, content: str) -> dict:
        """Parse objection handling scripts."""
        handlers = []

        section = self._extract_section(content, r'## 7\. Ð Ð°Ð±Ð¾Ñ‚Ð° Ñ Ð²Ð¾Ð·Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑÐ¼Ð¸')
        if not section or 'Ð½Ðµ Ð¿Ñ€Ð¾Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ñ‹' in section.lower():
            return {'objection_handlers': handlers}

        # Pattern: ### N. Â«ObjectionÂ»
        pattern = r'### \d+\. [Â«"](.+?)[Â»"]\n\n\*\*ÐžÑ‚Ð²ÐµÑ‚:\*\* (.+?)(?:\n\n\*\*Ð”Ð°Ð»ÐµÐµ:\*\* (.+?))?(?=\n### \d+\.|\Z)'
        for match in re.finditer(pattern, section, re.DOTALL):
            objection = match.group(1).strip()
            response = match.group(2).strip()
            follow_up = match.group(3).strip() if match.group(3) else None

            handlers.append(ObjectionHandler(
                objection=objection,
                response=response,
                follow_up=follow_up
            ))

        return {'objection_handlers': handlers}

    def _parse_sample_dialogue(self, content: str) -> dict:
        """Parse sample dialogue."""
        dialogue = []

        section = self._extract_section(content, r'## 8\. ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°')
        if not section or 'Ð½Ðµ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½' in section.lower():
            return {'sample_dialogue': dialogue}

        # Pattern: **Role:** Message *(intent)*
        pattern = r'\*\*(.+?):\*\* (.+?)(?:\s*\*\((.+?)\)\*)?(?=\n\n\*\*|\Z)'
        for match in re.finditer(pattern, section, re.DOTALL):
            role_str = match.group(1).strip()
            message = match.group(2).strip()
            intent = match.group(3).strip() if match.group(3) else None

            # Map role labels
            role = 'bot' if 'ÐÐ³ÐµÐ½Ñ‚' in role_str else 'client'

            dialogue.append(DialogueExample(
                role=role,
                message=message,
                intent=intent
            ))

        return {'sample_dialogue': dialogue}

    def _parse_financial_metrics(self, content: str) -> dict:
        """Parse financial metrics from table."""
        metrics = []

        section = self._extract_section(content, r'## 9\. Ð¤Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ')
        if not section or 'Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹' in section.lower():
            return {'financial_metrics': metrics}

        # Parse table: | ÐœÐµÑ‚Ñ€Ð¸ÐºÐ° | Ð—Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ | Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº | ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ |
        pattern = r'\| (.+?) \| (.+?) \| (.+?) \| (.+?) \|'
        for match in re.finditer(pattern, section):
            name = match.group(1).strip()
            value = match.group(2).strip()
            source_label = match.group(3).strip()
            note = match.group(4).strip()

            if name in ('ÐœÐµÑ‚Ñ€Ð¸ÐºÐ°', '-------'):
                continue

            # Map source labels back
            source_map = {
                'ÐšÐ»Ð¸ÐµÐ½Ñ‚': 'client',
                'AI-Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº': 'ai_benchmark',
                'Ð Ð°ÑÑ‡Ñ‘Ñ‚': 'calculated'
            }
            source = source_map.get(source_label, 'ai_benchmark')

            metrics.append(FinancialMetric(
                name=name,
                value=value,
                source=source,
                note=note if note != 'â€”' else None
            ))

        return {'financial_metrics': metrics}

    def _parse_market_analysis(self, content: str) -> dict:
        """Parse market analysis section."""
        result = {
            'competitors': [],
            'market_insights': [],
            'competitive_advantages': []
        }

        section = self._extract_section(content, r'## 10\. ÐÐ½Ð°Ð»Ð¸Ð· Ñ€Ñ‹Ð½ÐºÐ°')
        if not section:
            return result

        # Parse competitors
        competitors_section = re.search(
            r'### ÐšÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ñ‹\n\n(.+?)(?=\n### |\Z)',
            section, re.DOTALL
        )
        if competitors_section and 'Ð½Ðµ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ñ‹' not in competitors_section.group(1).lower():
            comp_content = competitors_section.group(1)
            # Parse each competitor: #### Name
            comp_pattern = r'#### (.+?)\n(?:\*Ð¦ÐµÐ½Ñ‹: (.+?)\*\n)?\n(.+?)(?=\n#### |\n### |\Z)'
            for match in re.finditer(comp_pattern, comp_content, re.DOTALL):
                name = match.group(1).strip()
                price_range = match.group(2).strip() if match.group(2) else None
                details = match.group(3)

                strengths = []
                weaknesses = []
                for line in details.split('\n'):
                    if 'âœ…' in line:
                        strengths.append(line.split('âœ…')[-1].strip())
                    elif 'âŒ' in line:
                        weaknesses.append(line.split('âŒ')[-1].strip())

                result['competitors'].append(Competitor(
                    name=name,
                    strengths=strengths,
                    weaknesses=weaknesses,
                    price_range=price_range
                ))

        # Parse market insights
        insights_section = re.search(
            r'### Ð Ñ‹Ð½Ð¾Ñ‡Ð½Ñ‹Ðµ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ñ‹\n\n(.+?)(?=\n### |\Z)',
            section, re.DOTALL
        )
        if insights_section and 'Ð½Ðµ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹' not in insights_section.group(1).lower():
            for line in insights_section.group(1).split('\n'):
                if line.startswith('- '):
                    insight_text = line[2:].strip()
                    # Remove emoji
                    for emoji in ['ðŸ”¥', 'ðŸ“Š', 'ðŸ“']:
                        insight_text = insight_text.replace(emoji, '').strip()

                    relevance = 'high' if 'ðŸ”¥' in line else ('medium' if 'ðŸ“Š' in line else 'low')
                    result['market_insights'].append(MarketInsight(
                        insight=insight_text,
                        relevance=relevance
                    ))

        # Parse competitive advantages
        advantages_section = re.search(
            r'### ÐšÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð½Ñ‹Ðµ Ð¿Ñ€ÐµÐ¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð° ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°\n\n(.+?)(?=\n---|\n## |\Z)',
            section, re.DOTALL
        )
        if advantages_section:
            result['competitive_advantages'] = self._parse_bullets(advantages_section.group(1))

        return result

    def _parse_target_segments(self, content: str) -> dict:
        """Parse target audience segments."""
        segments = []

        section = self._extract_section(content, r'## 11\. Ð¦ÐµÐ»ÐµÐ²Ñ‹Ðµ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ñ‹')
        if not section or 'Ð½Ðµ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ñ‹' in section.lower():
            return {'target_segments': segments}

        # Pattern: ### N. Segment Name
        pattern = r'### \d+\. (.+?)\n\n(.+?)(?=\n### \d+\.|\Z)'
        for match in re.finditer(pattern, section, re.DOTALL):
            name = match.group(1).strip()
            details = match.group(2)

            # Extract description (first paragraph before **Ð‘Ð¾Ð»ÐµÐ²Ñ‹Ðµ Ñ‚Ð¾Ñ‡ÐºÐ¸**)
            desc_match = re.match(r'(.+?)(?=\n\n\*\*Ð‘Ð¾Ð»ÐµÐ²Ñ‹Ðµ|\Z)', details, re.DOTALL)
            description = desc_match.group(1).strip() if desc_match else ''

            # Parse pain points and triggers
            pain_points = []
            triggers = []
            for line in details.split('\n'):
                if 'ðŸ˜“' in line:
                    pain_points.append(line.split('ðŸ˜“')[-1].strip())
                elif 'âš¡' in line:
                    triggers.append(line.split('âš¡')[-1].strip())

            segments.append(TargetAudienceSegment(
                name=name,
                description=description,
                pain_points=pain_points,
                triggers=triggers
            ))

        return {'target_segments': segments}

    def _parse_escalation_rules(self, content: str) -> dict:
        """Parse escalation rules from table."""
        rules = []

        section = self._extract_section(content, r'## 12\. ÐŸÑ€Ð°Ð²Ð¸Ð»Ð° ÑÑÐºÐ°Ð»Ð°Ñ†Ð¸Ð¸')
        if not section or 'Ð½Ðµ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ñ‹' in section.lower():
            return {'escalation_rules': rules}

        # Parse table rows
        pattern = r'\| (.+?) \| (.+?) \| (.+?) \|'
        for match in re.finditer(pattern, section):
            trigger = match.group(1).strip()
            urgency_label = match.group(2).strip()
            action = match.group(3).strip()

            if trigger in ('Ð¢Ñ€Ð¸Ð³Ð³ÐµÑ€', '-------'):
                continue

            # Map urgency labels
            urgency = 'medium'
            if 'ðŸš¨' in urgency_label or 'ÐÐµÐ¼ÐµÐ´Ð»ÐµÐ½Ð½Ð¾' in urgency_label:
                urgency = 'immediate'
            elif 'â°' in urgency_label or 'Ñ‡Ð°Ñ' in urgency_label:
                urgency = 'hour'
            elif 'ðŸ“…' in urgency_label or 'Ð´Ð½Ñ' in urgency_label:
                urgency = 'day'

            rules.append(EscalationRule(
                trigger=trigger,
                urgency=urgency,
                action=action
            ))

        return {'escalation_rules': rules}

    def _parse_success_kpis(self, content: str) -> dict:
        """Parse success KPIs from table."""
        kpis = []

        section = self._extract_section(content, r'## 13\. KPI Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÑƒÑÐ¿ÐµÑ…Ð°')
        if not section or 'Ð½Ðµ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ñ‹' in section.lower():
            return {'success_kpis': kpis}

        # Parse table: | KPI | Ð¦ÐµÐ»ÑŒ | Ð‘ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº | Ð˜Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ðµ |
        pattern = r'\| (.+?) \| (.+?) \| (.+?) \| (.+?) \|'
        for match in re.finditer(pattern, section):
            name = match.group(1).strip()
            target = match.group(2).strip()
            benchmark = match.group(3).strip()
            measurement = match.group(4).strip()

            if name in ('KPI', '----'):
                continue

            kpis.append(KPIMetric(
                name=name,
                target=target,
                benchmark=benchmark if benchmark != 'â€”' else None,
                measurement=measurement if measurement != 'â€”' else None
            ))

        return {'success_kpis': kpis}

    def _parse_launch_checklist(self, content: str) -> dict:
        """Parse launch checklist."""
        checklist = []

        section = self._extract_section(content, r'## 14\. Ð§ÐµÐºÐ»Ð¸ÑÑ‚ Ð·Ð°Ð¿ÑƒÑÐºÐ°')
        if not section or 'Ð½Ðµ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ñ‘Ð½' in section.lower():
            return {'launch_checklist': checklist}

        # Pattern: - â˜/â—‹ Item â€” Responsible **(Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾)**
        for line in section.split('\n'):
            if not line.strip().startswith('- '):
                continue

            required = 'â˜' in line or '**(Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾)**' in line
            text = line[2:].strip()

            # Remove checkbox symbols
            text = text.replace('â˜', '').replace('â—‹', '').strip()

            # Extract responsible
            responsible = 'client'
            if 'ðŸ‘¤ ÐšÐ»Ð¸ÐµÐ½Ñ‚' in text:
                responsible = 'client'
            elif 'ðŸ‘¥ ÐšÐ¾Ð¼Ð°Ð½Ð´Ð°' in text:
                responsible = 'team'
            elif 'ðŸ¤ Ð¡Ð¾Ð²Ð¼ÐµÑÑ‚Ð½Ð¾' in text:
                responsible = 'both'

            # Clean item text
            item_text = re.sub(r'\s*â€”\s*(ðŸ‘¤ ÐšÐ»Ð¸ÐµÐ½Ñ‚|ðŸ‘¥ ÐšÐ¾Ð¼Ð°Ð½Ð´Ð°|ðŸ¤ Ð¡Ð¾Ð²Ð¼ÐµÑÑ‚Ð½Ð¾).*', '', text).strip()

            if item_text:
                checklist.append(ChecklistItem(
                    item=item_text,
                    required=required,
                    responsible=responsible
                ))

        return {'launch_checklist': checklist}

    def _parse_ai_recommendations(self, content: str) -> dict:
        """Parse AI recommendations."""
        recommendations = []

        section = self._extract_section(content, r'## 15\. Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ AI-ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð°')
        if not section or 'Ð½Ðµ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹' in section.lower():
            return {'ai_recommendations': recommendations}

        # Pattern: ### N. Priority Recommendation
        pattern = r'### \d+\. (?:ðŸ”´|ðŸŸ¡|ðŸŸ¢)?\s*(.+?)\n\n\*\*ÐžÐ¶Ð¸Ð´Ð°ÐµÐ¼Ñ‹Ð¹ ÑÑ„Ñ„ÐµÐºÑ‚:\*\* (.+?)\n\n\*ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚: (\w+) \| Ð—Ð°Ñ‚Ñ€Ð°Ñ‚Ñ‹: (\w+)\*'
        for match in re.finditer(pattern, section, re.DOTALL):
            recommendation = match.group(1).strip()
            impact = match.group(2).strip()
            priority = match.group(3).strip()
            effort_label = match.group(4).strip()

            # Map effort labels
            effort_map = {'ÐÐ¸Ð·ÐºÐ¸Ðµ': 'low', 'Ð¡Ñ€ÐµÐ´Ð½Ð¸Ðµ': 'medium', 'Ð’Ñ‹ÑÐ¾ÐºÐ¸Ðµ': 'high'}
            effort = effort_map.get(effort_label, 'medium')

            recommendations.append(AIRecommendation(
                recommendation=recommendation,
                impact=impact,
                priority=priority,
                effort=effort
            ))

        return {'ai_recommendations': recommendations}

    def _parse_tone_of_voice(self, content: str) -> dict:
        """Parse tone of voice guidelines."""
        tone = {}

        section = self._extract_section(content, r'## 16\. Ð¢Ð¾Ð½ ÐºÐ¾Ð¼Ð¼ÑƒÐ½Ð¸ÐºÐ°Ñ†Ð¸Ð¸')
        if not section or 'Ð½Ðµ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ñ‘Ð½' in section.lower():
            return {'tone_of_voice': tone}

        # Parse Do section
        do_match = re.search(r'### âœ… Ð”ÐµÐ»Ð°Ñ‚ÑŒ\n\n(.+?)(?=\n### |$)', section, re.DOTALL)
        if do_match:
            tone['do'] = do_match.group(1).strip()

        # Parse Don't section
        dont_match = re.search(r'### âŒ ÐÐµ Ð´ÐµÐ»Ð°Ñ‚ÑŒ\n\n(.+?)(?=\n### |\n---|\Z)', section, re.DOTALL)
        if dont_match:
            tone['dont'] = dont_match.group(1).strip()

        return {'tone_of_voice': tone}

    def _parse_error_handling_scripts(self, content: str) -> dict:
        """Parse error handling scripts."""
        scripts = {}

        section = self._extract_section(content, r'## 17\. Ð¡ÐºÑ€Ð¸Ð¿Ñ‚Ñ‹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¾ÑˆÐ¸Ð±Ð¾Ðº')
        if not section or 'Ð½Ðµ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ñ‹' in section.lower():
            return {'error_handling_scripts': scripts}

        # Parse each script block
        label_map = {
            'ðŸ¤” ÐÐµ Ð¿Ð¾Ð½ÑÐ» Ð·Ð°Ð¿Ñ€Ð¾Ñ': 'not_understood',
            'âš ï¸ Ð¢ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°': 'technical_issue',
            'ðŸš« Ð’Ð½Ðµ ÐºÐ¾Ð¼Ð¿ÐµÑ‚ÐµÐ½Ñ†Ð¸Ð¸': 'out_of_scope'
        }

        for label, key in label_map.items():
            pattern = rf'\*\*{re.escape(label)}:\*\*\n> [Â«"](.+?)[Â»"]'
            match = re.search(pattern, section)
            if match:
                scripts[key] = match.group(1).strip()

        return {'error_handling_scripts': scripts}

    def _parse_follow_up_sequence(self, content: str) -> dict:
        """Parse follow-up sequence."""
        section = self._extract_section(content, r'## 18\. ÐŸÐ¾ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ follow-up')
        if not section:
            return {'follow_up_sequence': []}

        return {'follow_up_sequence': self._parse_bullets(section)}

    # =========================================================================
    # HELPER METHODS
    # =========================================================================

    def _extract_section(self, content: str, header_pattern: str) -> Optional[str]:
        """Extract section content by header pattern."""
        pattern = rf'{header_pattern}\n\n(.+?)(?=\n---|\n## |\Z)'
        match = re.search(pattern, content, re.DOTALL)
        return match.group(1).strip() if match else None

    def _parse_bullets(self, text: str) -> List[str]:
        """Parse bullet points from text."""
        items = []
        for line in text.split('\n'):
            line = line.strip()
            if line.startswith('- '):
                item = line[2:].strip()
                # Clean emoji prefixes
                for emoji in ['ðŸ˜“', 'âš¡', 'âœ…', 'âŒ', 'ðŸ”¥', 'ðŸ“Š', 'ðŸ“', 'â˜', 'â—‹']:
                    item = item.replace(emoji, '').strip()
                if item and item != '*ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾*':
                    items.append(item)
        return items


def parse_anketa_markdown(content: str, base: FinalAnketa) -> FinalAnketa:
    """
    Convenience function to parse markdown into anketa.

    Args:
        content: Markdown content
        base: Base anketa to merge with

    Returns:
        Updated FinalAnketa
    """
    parser = AnketaMarkdownParser()
    return parser.parse(content, base)
